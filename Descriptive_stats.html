<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Descriptive statistics</title>

<script src="site_libs/header-attrs-2.6/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/readable.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 66px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h2 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h3 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h4 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h5 {
  padding-top: 71px;
  margin-top: -71px;
}
.section h6 {
  padding-top: 71px;
  margin-top: -71px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html"></a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fas fa-home"></span>
     
    Home
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://osf.io/7n4qj">
    <span class="fas fa-hand-spock-o"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Descriptive statistics</h1>

</div>


<style>
body{
  font-family: 'Oxygen', sans-serif;
  font-size: 16px;
  line-height: 24px;
}
</style>
<p><span class="math display">\[\\[0.5in]\]</span></p>
<p><em>Here we calculate descriptive statistics for the brain networks.</em></p>
<p><span class="math display">\[\\[1in]\]</span></p>
<hr />
<p><br> <br></p>
<div id="phenotyic-brain-networks" class="section level1">
<h1>Phenotyic brain networks</h1>
<div id="eigendecomposition" class="section level2">
<h2>Eigendecomposition</h2>
<pre class="r"><code># set wd to where region names per network are saved
workingd&lt;-getwd()
temporarywd&lt;-paste0(workingd,&quot;/Scripts/my_own_gwas/2Perform_ldsc&quot;)
setwd(temporarywd)

# load files containing region names
central_exec_regions&lt;-read.table(&quot;central_executive_areas.txt&quot;)$V1
cingulo_regions&lt;-read.table(&quot;cingulo_opercular_areas.txt&quot;)$V1
default_regions&lt;-read.table(&quot;default_mode_areas.txt&quot;)$V1
hippocampal_regions&lt;-read.table(&quot;hippocampal_diencephalic_areas.txt&quot;)$V1
multiple_demand_regions&lt;-read.table(&quot;multiple_demand_areas.txt&quot;)$V1
p_fit_regions&lt;-read.table(&quot;p_fit_areas.txt&quot;)$V1
salience_regions&lt;-read.table(&quot;salience_areas.txt&quot;)$V1
sensori_regions&lt;-read.table(&quot;sensorimotor_areas.txt&quot;)$V1
temporo_regions&lt;-read.table(&quot;temporo_amygdala_orbitofrontal_areas.txt&quot;)$V1

# list the files
region_files&lt;-ls(pattern=&quot;regions&quot;)

# create a dataframe to hold results
library(stringr)
descriptives_pheno_networks&lt;-data.frame(networks=str_replace(region_files,pattern=&quot;_regions&quot;,replacement = &quot;&quot;))

# load phenotypic correlation matrix
temporarywd_pheno&lt;-paste0(workingd,&quot;/data_my_own/Pheno_preparation/&quot;)
setwd(temporarywd_pheno)

load(&quot;pheno_decomposition.RData&quot;)


for(i in region_files){
  #print(i)
  regions&lt;-get(i)
  
  # get network specific matrix
  matrix&lt;-cor_matrix[regions,regions]

  #calculate eigenvectors, eigenvalues and explained variances
  eigenvectors&lt;-eigen(matrix)$vectors
  eigenvalues&lt;-eigen(matrix)$values
  explained_variance&lt;-round(eigenvalues/sum(eigenvalues)*100,digits = 3)
  #print(explained_variance)
  
  # save explained variance in object &quot;descriptives_pheno_networks&quot; in the appropriate row for each network
  network_name&lt;-str_replace(i,pattern=&quot;_regions&quot;,replacement = &quot;&quot;)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == network_name),&quot;R2&quot;]&lt;-explained_variance[1]
  
  # calculate standardised PC loadings 
  stand_loadings&lt;-eigenvectors%*%sqrt(diag(eigenvalues))
  stand_loadings&lt;-stand_loadings[,1]
  
  # switch sign of stand loadings if median is negative
  if(sign(median(stand_loadings))==-1){
    stand_loadings&lt;-stand_loadings*(-1)
  } else {
    stand_loadings&lt;-stand_loadings
  }
  
  # save stand loadings for plot
  name_to_save&lt;-paste0(network_name,&quot;_pheno_loadings&quot;)
  assign(name_to_save,stand_loadings)
  
  # calculate mean,sd,median,min,max and save in object
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == network_name),&quot;mean&quot;]&lt;-mean(stand_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == network_name),&quot;SD&quot;]&lt;-sd(stand_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == network_name),&quot;median&quot;]&lt;-median(stand_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == network_name),&quot;max&quot;]&lt;-max(stand_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == network_name),&quot;min&quot;]&lt;-min(stand_loadings)
  
  #calculate mode
    d&lt;-density(stand_loadings)
    descriptives_pheno_networks[which(descriptives_pheno_networks$networks == network_name),&quot;mode&quot;]&lt;-d$x[which.max(d$y)]
}

# add empty row to descriptives_pheno_networks
descriptives_pheno_networks[nrow(descriptives_pheno_networks)+1,]&lt;-NA
descriptives_pheno_networks[which(is.na(descriptives_pheno_networks$networks)),&quot;networks&quot;]&lt;-&quot;whole_brain&quot;

# eigendecomposition for the whole brain 
eigenvectors&lt;-eigen(cor_matrix)$vectors
eigenvalues&lt;-eigen(cor_matrix)$values
explained_variance&lt;-round(eigenvalues/sum(eigenvalues)*100,digits = 3)
descriptives_pheno_networks[which(descriptives_pheno_networks$networks == &quot;whole_brain&quot;),&quot;R2&quot;]&lt;-explained_variance[1]

# calculate standardised PC loadings 
  stand_loadings&lt;-eigenvectors%*%sqrt(diag(eigenvalues))
  whole_brain_pheno_loadings&lt;-stand_loadings[,1]*(-1)

# descriptive stats for the whole brain 
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == &quot;whole_brain&quot;),&quot;mean&quot;]&lt;-mean(whole_brain_pheno_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == &quot;whole_brain&quot;),&quot;SD&quot;]&lt;-sd(whole_brain_pheno_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == &quot;whole_brain&quot;),&quot;median&quot;]&lt;-median(whole_brain_pheno_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == &quot;whole_brain&quot;),&quot;max&quot;]&lt;-max(whole_brain_pheno_loadings)
  descriptives_pheno_networks[which(descriptives_pheno_networks$networks == &quot;whole_brain&quot;),&quot;min&quot;]&lt;-min(whole_brain_pheno_loadings)

  #calculate mode
    d&lt;-density(whole_brain_pheno_loadings)
    descriptives_pheno_networks[which(descriptives_pheno_networks$networks == &quot;whole_brain&quot;),&quot;mode&quot;]&lt;-d$x[which.max(d$y)]

kable(descriptives_pheno_networks, digits = 2)</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">networks</th>
<th align="right">R2</th>
<th align="right">mean</th>
<th align="right">SD</th>
<th align="right">median</th>
<th align="right">max</th>
<th align="right">min</th>
<th align="right">mode</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">central_exec</td>
<td align="right">53.06</td>
<td align="right">0.73</td>
<td align="right">0.06</td>
<td align="right">0.74</td>
<td align="right">0.78</td>
<td align="right">0.64</td>
<td align="right">0.77</td>
</tr>
<tr class="even">
<td align="left">cingulo</td>
<td align="right">38.69</td>
<td align="right">0.60</td>
<td align="right">0.17</td>
<td align="right">0.70</td>
<td align="right">0.78</td>
<td align="right">0.33</td>
<td align="right">0.72</td>
</tr>
<tr class="odd">
<td align="left">default</td>
<td align="right">36.49</td>
<td align="right">0.59</td>
<td align="right">0.13</td>
<td align="right">0.61</td>
<td align="right">0.76</td>
<td align="right">0.40</td>
<td align="right">0.67</td>
</tr>
<tr class="even">
<td align="left">hippocampal</td>
<td align="right">38.09</td>
<td align="right">0.61</td>
<td align="right">0.10</td>
<td align="right">0.58</td>
<td align="right">0.76</td>
<td align="right">0.50</td>
<td align="right">0.54</td>
</tr>
<tr class="odd">
<td align="left">multiple_demand</td>
<td align="right">41.17</td>
<td align="right">0.63</td>
<td align="right">0.15</td>
<td align="right">0.68</td>
<td align="right">0.77</td>
<td align="right">0.34</td>
<td align="right">0.68</td>
</tr>
<tr class="even">
<td align="left">p_fit</td>
<td align="right">34.12</td>
<td align="right">0.57</td>
<td align="right">0.12</td>
<td align="right">0.57</td>
<td align="right">0.74</td>
<td align="right">0.30</td>
<td align="right">0.56</td>
</tr>
<tr class="odd">
<td align="left">salience</td>
<td align="right">44.43</td>
<td align="right">0.63</td>
<td align="right">0.22</td>
<td align="right">0.67</td>
<td align="right">0.84</td>
<td align="right">0.24</td>
<td align="right">0.78</td>
</tr>
<tr class="even">
<td align="left">sensori</td>
<td align="right">45.62</td>
<td align="right">0.67</td>
<td align="right">0.07</td>
<td align="right">0.67</td>
<td align="right">0.79</td>
<td align="right">0.56</td>
<td align="right">0.67</td>
</tr>
<tr class="odd">
<td align="left">temporo</td>
<td align="right">32.20</td>
<td align="right">0.55</td>
<td align="right">0.12</td>
<td align="right">0.56</td>
<td align="right">0.74</td>
<td align="right">0.34</td>
<td align="right">0.64</td>
</tr>
<tr class="even">
<td align="left">whole_brain</td>
<td align="right">30.93</td>
<td align="right">0.55</td>
<td align="right">0.11</td>
<td align="right">0.56</td>
<td align="right">0.73</td>
<td align="right">0.29</td>
<td align="right">0.59</td>
</tr>
</tbody>
</table>
<p><br></p>
</div>
<div id="plot-density-distribution-of-standardised-loadings" class="section level2">
<h2>Plot density distribution of standardised loadings</h2>
<pre class="r"><code>data_pheno&lt;-data.frame(matrix(ncol=2))
colnames(data_pheno)&lt;-c(&quot;stand_loadings&quot;,&quot;network&quot;)

rm(&quot;regions_pheno_loadings&quot;)
loadings_pheno&lt;-ls(pattern=&quot;pheno_loadings&quot;)
#names&lt;-str_remove(loadings_pheno, pattern=&quot;_pheno_loadings&quot;)
#data_pheno$network&lt;-names

for(i in loadings_pheno){
  df&lt;-get(i)
  df&lt;-unlist(df)
  #print(df)
  network&lt;-str_remove(i, pattern=&quot;_pheno_loadings&quot;)
  #print(network)
  df&lt;-cbind(df,network)
  colnames(df)&lt;-c(&quot;stand_loadings&quot;,&quot;network&quot;)
  #print(df)
  #assign(i,df)
  data_pheno&lt;-rbind(data_pheno,df)
}

# remove empty first row
data_pheno&lt;-data_pheno[-1,]

# print full names for networks
data_pheno$network[which(data_pheno$network == &quot;temporo&quot;)]&lt;-&quot;Temporo-amygdala-orbitofrontal&quot;
data_pheno$network[which(data_pheno$network == &quot;sensori&quot;)]&lt;-&quot;Sensorimotor&quot;
data_pheno$network[which(data_pheno$network == &quot;salience&quot;)]&lt;-&quot;Salience&quot;
data_pheno$network[which(data_pheno$network == &quot;p_fit&quot;)]&lt;-&quot;P-FIT&quot;
data_pheno$network[which(data_pheno$network == &quot;multiple_demand&quot;)]&lt;-&quot;Multiple demand&quot;
data_pheno$network[which(data_pheno$network == &quot;hippocampal&quot;)]&lt;-&quot;Hippocampal-diencephalic&quot;
data_pheno$network[which(data_pheno$network == &quot;default&quot;)]&lt;-&quot;Default mode&quot;
data_pheno$network[which(data_pheno$network == &quot;cingulo&quot;)]&lt;-&quot;Cingulo-opercular&quot;
data_pheno$network[which(data_pheno$network == &quot;central_exec&quot;)]&lt;-&quot;Central executive&quot;
data_pheno$network[which(data_pheno$network == &quot;whole_brain&quot;)]&lt;-&quot;Whole brain&quot;

# adjust data structure
data_pheno$network&lt;-as.factor(data_pheno$network)
data_pheno$stand_loadings&lt;-as.numeric(data_pheno$stand_loadings)

library(ggplot2)
library(RColorBrewer)
library(ggridges)

# Define the number of colors you want
nb.cols &lt;- 10
mycolors &lt;- colorRampPalette(brewer.pal(8, &quot;Pastel1&quot;))(nb.cols)

# save plot

#tiff(&quot;PC_pheno_loadings.tiff&quot;, width = 6.25, height = 5, units = &#39;in&#39;, res=1000)

 loadings_pheno_plot&lt;-ggplot(data_pheno, aes(x=stand_loadings,y=network))+
              geom_density_ridges(rel_min_height = 0.005, aes(fill=as.factor(network)),stat=&quot;density_ridges&quot;, position = &quot;identity&quot;, quantile_lines =TRUE,na.rm=TRUE, n=nrow(data_pheno)) +
              theme_ridges()+
              #scale_fill_brewer(values = mycolors)+
              scale_fill_manual(values=mycolors,guide=FALSE)+
              scale_x_continuous(n.breaks = 5)+
              xlab(&quot;Phenotypic PC loadings&quot;)+ylab(&quot;&quot;)+
              theme(legend.position = &quot;none&quot;,
                    axis.text.x = element_text(size=24),
                    axis.text.y = element_text(size=24),
                    axis.title.x = element_text(size=26),
                    panel.background = element_blank(), 
                    axis.line = element_line(color=&quot;black&quot;), 
                    axis.line.x = element_line(color=&quot;black&quot;))+theme_bw() 
loadings_pheno_plot</code></pre>
<p><img src="Descriptive_stats_files/figure-html/pheno_PC_plot-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Note that the vertical lines indicate quantiles.</p>
<hr />
<p><br> <br></p>
</div>
</div>
<div id="genetic-brain-networks" class="section level1">
<h1>Genetic brain networks</h1>
<div id="eigendecomposition-1" class="section level2">
<h2>Eigendecomposition</h2>
<pre class="r"><code>### eigen decomposition of networks
rm(list=ls())
library(stringr)
library(data.table)

# set wd where ldsc_output is saved
workingd&lt;-getwd()
temporarywd&lt;-paste0(workingd,&quot;/data_my_own/ldsc/&quot;)
setwd(temporarywd)

# list available results in this directory
networks&lt;-list.files(pattern=&quot;.RData&quot;)
network_names&lt;-str_replace(networks,pattern=&quot;.RData&quot;,replacement = &quot;&quot;)

# load results and name them after their corresponding network
for(i in 1:length(networks)){
  load(networks[i])
  name&lt;-network_names[i]
    if(name == &quot;whole_brain&quot;){
      assign(name,LDSCoutput_wholebrain)
    }else{
      assign(name,LDSCoutput)
    }
}

# name rows and columns in matrices after their corresponding brain area
for(i in network_names){
  output&lt;-get(i)
  dimnames(output$S_Stand)[[1]]&lt;-dimnames(output$S)[[2]]
  dimnames(output$S_Stand)[[2]]&lt;-dimnames(output$S)[[2]]
  name&lt;-i
  assign(name,output)
  output$S_Stand&lt;-round(output$S_Stand,digits = 2)
  name_cor&lt;-paste0(&quot;cor_&quot;,i)
  assign(name_cor,output$S_Stand)
}

# list matrices of interest
matrices&lt;-ls(pattern=&quot;cor_&quot;)

#create data frame with names of ldscoutput and names of correlation matrices
networks&lt;-data.frame(cbind(matrices,network_names))

#######################################################
##### networks
#######################################################

for(i in 1:nrow(networks)){
    #### calculate eigenvectors
    # get correlation matrix of interest
    cormatrix&lt;-get(matrices[i])
    
    # extract eigenvectors
    eigenvectors&lt;-eigen(cormatrix)$vectors
    
    # get ldsc_output as it contains correct names (columns named after brain areas)
    noi&lt;-get(network_names[i])
    
    # rename rows and columns with brain areas
    rownames(eigenvectors)&lt;-dimnames(noi$S)[[2]]
    colnames(eigenvectors)&lt;-dimnames(noi$S)[[2]]
    
    # save to network-specific variable name &quot;eigenvectors&quot;
    name&lt;-paste0(&quot;eigenvectors_&quot;,network_names[i])
    assign(name,eigenvectors)
    
    ### calculate eigenvalues
    # extract eigenvalues
    eigenvalues&lt;-eigen(cormatrix)$values
    
    # save to network-specific variable name &quot;eigenvalues&quot;
    name&lt;-paste0(&quot;eigenvalues_&quot;,network_names[i])
    assign(name,eigenvalues)

    ### calculate explained_variances
    explained_variance&lt;-round(eigenvalues/sum(eigenvalues)*100,digits = 3)
    name&lt;-paste0(&quot;explained_var_&quot;,network_names[i])
    assign(name,explained_variance)
    
    ### calculate standardised loadings on first PC
    stand_loadings&lt;-eigenvectors%*%sqrt(diag(eigenvalues))
    stand_loadings&lt;-setDT(as.data.frame(stand_loadings), keep.rownames = TRUE)[,1:2]
    names(stand_loadings)&lt;-c(&quot;Regions&quot;,&quot;stand_loadings&quot;)
  
    ### flip the loadings if median loadings are negative
    median_loadings&lt;-median(stand_loadings$stand_loadings)
    mean_direction&lt;-sign(median_loadings)
    if(mean_direction == -1){
    stand_loadings$stand_loadings&lt;-stand_loadings$stand_loadings*(-1)
    } else {
    stand_loadings$stand_loadings&lt;-stand_loadings$stand_loadings}

    name&lt;-paste0(&quot;stand_loadings_&quot;,network_names[i])
    assign(name,stand_loadings)
    }

rm(&quot;stand_loadings&quot;)
loadings_all_traits&lt;-ls(pattern=&quot;stand_loadings&quot;)

rm(&quot;explained_variance&quot;)
explained_all_traits&lt;-ls(pattern=&quot;explained_var&quot;)</code></pre>
<div id="save-pc-loadings-in-separate-files" class="section level4">
<h4>Save PC loadings in separate files</h4>
<p>PC loadings are saved in a separate file to be able to create the network specific summary statistics in a <a href="Hypothesis3.html">later step</a>, in which multiple regions are combined and weighted according to their PC loadings.</p>
<pre class="r"><code>setwd(paste0(workingd,&quot;data_my_own/standardised_loadings/&quot;))

for (i in loadings_all_traits){
    loadings&lt;-get(i)
    file_name&lt;-paste0(i,&quot;.txt&quot;)
    write.table(loadings,file=file_name,quote=F,sep=&quot; &quot;,na=&quot;NA&quot;,row.names=F,col.names = T)
}</code></pre>
<pre class="r"><code># display the results in a table
library(knitr)

# create new dataframe with network names in one row
table&lt;-data.frame(networks=&quot;test&quot;,matrix(nrow=10))[1]
table$networks&lt;-str_replace(loadings_all_traits,pattern=&quot;stand_loadings_&quot;,replacement=&quot;&quot;)

for(i in 1:length(loadings_all_traits)){
    
    # store explained var by first PC in every network
    explained&lt;-get(explained_all_traits[i])
    table$explained[i]&lt;-explained[1]
    
    # calculate summary data and store in dataframe
    loadings&lt;-get(loadings_all_traits[i])
    table$min[i]&lt;-min(loadings$stand_loadings)
    table$mean[i]&lt;-mean(loadings$stand_loadings)
    table$sd[i]&lt;-sd(loadings$stand_loadings)
    table$median[i]&lt;-median(loadings$stand_loadings)
    
    #calculate mode
    d&lt;-density(loadings$stand_loadings)
    table$mode[i]&lt;-d$x[which.max(d$y)]  
    
    table$max[i]&lt;-max(loadings$stand_loadings)
    

}

table$number_included&lt;-c(8,10,16,12,12,36,10,12,30,83)


kable(table,caption=&quot;Explained variance and loadings on first PC&quot;,format=&quot;markdown&quot;,digits=3,row.names = F)</code></pre>
<table>
<caption>Explained variance and loadings on first PC</caption>
<thead>
<tr class="header">
<th align="left">networks</th>
<th align="right">explained</th>
<th align="right">min</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">median</th>
<th align="right">mode</th>
<th align="right">max</th>
<th align="right">number_included</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">central_exec</td>
<td align="right">65.228</td>
<td align="right">0.736</td>
<td align="right">0.806</td>
<td align="right">0.058</td>
<td align="right">0.809</td>
<td align="right">0.850</td>
<td align="right">0.882</td>
<td align="right">8</td>
</tr>
<tr class="even">
<td align="left">cingulo</td>
<td align="right">47.501</td>
<td align="right">0.517</td>
<td align="right">0.680</td>
<td align="right">0.119</td>
<td align="right">0.668</td>
<td align="right">0.663</td>
<td align="right">0.898</td>
<td align="right">10</td>
</tr>
<tr class="odd">
<td align="left">default_mode</td>
<td align="right">51.777</td>
<td align="right">0.421</td>
<td align="right">0.709</td>
<td align="right">0.127</td>
<td align="right">0.745</td>
<td align="right">0.774</td>
<td align="right">0.848</td>
<td align="right">16</td>
</tr>
<tr class="even">
<td align="left">hippocampal</td>
<td align="right">47.632</td>
<td align="right">0.644</td>
<td align="right">0.689</td>
<td align="right">0.039</td>
<td align="right">0.679</td>
<td align="right">0.662</td>
<td align="right">0.744</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">multiple</td>
<td align="right">55.232</td>
<td align="right">0.482</td>
<td align="right">0.734</td>
<td align="right">0.123</td>
<td align="right">0.767</td>
<td align="right">0.784</td>
<td align="right">0.876</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="left">p_fit</td>
<td align="right">47.560</td>
<td align="right">0.430</td>
<td align="right">0.684</td>
<td align="right">0.090</td>
<td align="right">0.689</td>
<td align="right">0.685</td>
<td align="right">0.826</td>
<td align="right">36</td>
</tr>
<tr class="odd">
<td align="left">salience</td>
<td align="right">49.051</td>
<td align="right">0.474</td>
<td align="right">0.689</td>
<td align="right">0.130</td>
<td align="right">0.730</td>
<td align="right">0.765</td>
<td align="right">0.861</td>
<td align="right">10</td>
</tr>
<tr class="even">
<td align="left">sensori</td>
<td align="right">55.415</td>
<td align="right">0.429</td>
<td align="right">0.729</td>
<td align="right">0.156</td>
<td align="right">0.792</td>
<td align="right">0.814</td>
<td align="right">0.891</td>
<td align="right">12</td>
</tr>
<tr class="odd">
<td align="left">temporo</td>
<td align="right">46.921</td>
<td align="right">0.412</td>
<td align="right">0.673</td>
<td align="right">0.127</td>
<td align="right">0.719</td>
<td align="right">0.755</td>
<td align="right">0.845</td>
<td align="right">30</td>
</tr>
<tr class="even">
<td align="left">whole_brain</td>
<td align="right">39.667</td>
<td align="right">0.303</td>
<td align="right">0.617</td>
<td align="right">0.129</td>
<td align="right">0.653</td>
<td align="right">0.702</td>
<td align="right">0.814</td>
<td align="right">83</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="plot-density-distribution-of-standardised-loadings-1" class="section level2">
<h2>Plot density distribution of standardised loadings</h2>
<pre class="r"><code># all networks are saved in loadings_all_traits

# add a column indicating network name to each df containing standardised loadings and volume names 
# and save all in the same df called data_ridges
data_ridges&lt;-data.frame(matrix(ncol=3))
colnames(data_ridges)&lt;-c(&quot;Regions&quot;,&quot;stand_loadings&quot;,&quot;network&quot;)

for(i in loadings_all_traits){
  df&lt;-get(i)
  name&lt;-str_remove(i, pattern=&quot;stand_loadings_&quot;)
  df$network&lt;-name
  #assign(i,df)
  data_ridges&lt;-rbind(data_ridges,df)
}

# remove empty first row
data_ridges&lt;-data_ridges[-1,]

# print full names for networks
data_ridges$network[which(data_ridges$network == &quot;temporo&quot;)]&lt;-&quot;Temporo-amygdala-orbitofrontal&quot;
data_ridges$network[which(data_ridges$network == &quot;sensori&quot;)]&lt;-&quot;Sensorimotor&quot;
data_ridges$network[which(data_ridges$network == &quot;salience&quot;)]&lt;-&quot;Salience&quot;
data_ridges$network[which(data_ridges$network == &quot;p_fit&quot;)]&lt;-&quot;P-FIT&quot;
data_ridges$network[which(data_ridges$network == &quot;multiple&quot;)]&lt;-&quot;Multiple demand&quot;
data_ridges$network[which(data_ridges$network == &quot;hippocampal&quot;)]&lt;-&quot;Hippocampal-diencephalic&quot;
data_ridges$network[which(data_ridges$network == &quot;default_mode&quot;)]&lt;-&quot;Default mode&quot;
data_ridges$network[which(data_ridges$network == &quot;cingulo&quot;)]&lt;-&quot;Cingulo-opercular&quot;
data_ridges$network[which(data_ridges$network == &quot;central_exec&quot;)]&lt;-&quot;Central executive&quot;
data_ridges$network[which(data_ridges$network == &quot;whole_brain&quot;)]&lt;-&quot;Whole brain&quot;


data_ridges$network&lt;-as.factor(data_ridges$network)

library(ggplot2)
library(RColorBrewer)
library(ggridges)

# Define the number of colors you want
nb.cols &lt;- 10
mycolors &lt;- colorRampPalette(brewer.pal(8, &quot;Pastel1&quot;))(nb.cols)

# save plot

#tiff(&quot;PC_loadings.tiff&quot;, width = 6.25, height = 5, units = &#39;in&#39;, res=1000)

 loadings_plot&lt;-ggplot(data_ridges, aes(x=stand_loadings,y=network))+
              geom_density_ridges(rel_min_height = 0.005, aes(fill=as.factor(network)),stat=&quot;density_ridges&quot;, position = &quot;identity&quot;, quantile_lines =TRUE,na.rm=TRUE, n=nrow(data_ridges)) +
              theme_ridges()+
              #scale_fill_brewer(values = mycolors)+
              scale_fill_manual(values=mycolors,guide=FALSE)+
              scale_x_continuous(n.breaks = 5)+
              xlab(&quot;Genetic PC loadings&quot;)+ylab(&quot;&quot;)+
              theme(legend.position = &quot;none&quot;,
                    axis.text.x = element_text(size=24),
                    axis.text.y = element_text(size=24),
                    axis.title.x = element_text(size=26),
                    panel.background = element_blank(), 
                    axis.line = element_line(color=&quot;black&quot;), 
                    axis.line.x = element_line(color=&quot;black&quot;))+theme_bw() 
loadings_plot</code></pre>
<p><img src="Descriptive_stats_files/figure-html/plot_density_stand_loadings-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#dev.off()</code></pre>
<p>Note that the vertical lines indicate quantiles.</p>
<hr />
<p><br> <br></p>
</div>
<div id="parallel-analysis-for-genetic-networks" class="section level2">
<h2>Parallel analysis for genetic networks</h2>
<p>We test whether genetic PCs explain more variance than 95% of the corresponding PCs generated under a null model in a parallel analysis. We developed a version of parallel analysis to generate null distributions of eigenvalues by simulating null correlation matrices sampled from a diagonal population matrix, where the multivariate sampling distribution is specified to take the form of the sampling distribution of the standardized empirical genetic correlation matrix (V_Stand = sampling correlation matrix; S_Stand = genetic correlation matrix, as estimated using the ldsc function in GenomicSEM). This sampling correlation matrix (V_stand) serves as an index of the precision of and dependencies among genetic correlations when generating the random null data sets. We specify 1,000 replications to simulate the null correlation matrices and use a 95% threshold for distinguishing true eigenvalues from noise.</p>
<pre class="r"><code># load dependencies
library(stringr)

# load Javiers function
workingd&lt;-getwd()
temporarywd&lt;-paste0(workingd,&quot;/Scripts/my_own_gwas/Eigendecomp/&quot;)
setwd(temporarywd)

source(&quot;Parallel_Anallysis_paLDSC_JF.R&quot;)

# load data and name it according to network
temporarywd&lt;-paste0(workingd,&quot;/data_my_own/ldsc/&quot;)
setwd(temporarywd)

networks&lt;-list.files(pattern=&quot;.RData&quot;)
network_names&lt;-str_replace(networks,pattern=&quot;.RData&quot;,replacement = &quot;&quot;)

for(i in 1:length(networks)){
load(networks[i])
  name&lt;-network_names[i]
  assign(name,LDSCoutput)
}

temporarywd&lt;-paste0(workingd,&quot;/data_my_own/PA_output/&quot;)
setwd(temporarywd)


for(i in network_names){
        ldsc_output&lt;-get(i)
        paLDSC(S_Stand = ldsc_output$S_Stand, V_Stand = ldsc_output$V_Stand, r = 1000, p = .95, diag = F, fa = F, fm = &quot;minres&quot;, save.pdf = T)
        name&lt;-paste0(&quot;Parallel_analysis_&quot;,i,&quot;.pdf&quot;)
        file.rename(&quot;PCA_PA_LDSC.pdf&quot;,name)
}</code></pre>
<p><br/></p>
<div class="figure">
<img src="central_exec_PA.png" alt="" />
<p class="caption">Parallel analysis: Central Executive network</p>
</div>
<p><br/></p>
<div class="figure">
<img src="cingulo_PA.PNG" alt="" />
<p class="caption">Parallel analysis: Cingulo-opercular network</p>
</div>
<p><br/></p>
<div class="figure">
<img src="default_mode_PA.PNG" alt="" />
<p class="caption">Parallel analysis: Default mode network</p>
</div>
<p><br/></p>
<div class="figure">
<img src="Whole_brain_PA.PNG" alt="" />
<p class="caption">Parallel analysis: Whole-brain network (suggesting to extract 14 components)</p>
</div>
<p><br/></p>
</div>
</div>
<div id="exploratory-analyses" class="section level1">
<h1>Exploratory analyses</h1>
<div id="the-first-pc-of-larger-networks-explains-less-variance-than-the-pc-of-smaller-networks" class="section level3">
<h3>The first PC of larger networks explains less variance than the PC of smaller networks</h3>
<pre class="r"><code>volumes&lt;-table$number_included
explained_var&lt;-table$explained


cor.test(volumes,explained_var)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  volumes and explained_var
## t = -2.5803, df = 8, p-value = 0.0326
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  -0.9152174 -0.0770015
## sample estimates:
##        cor 
## -0.6739531</code></pre>
<pre class="r"><code>plot(volumes,explained_var,ylab=&quot;Explained variance by first PC&quot;,xlab=&quot;Number of included volumes&quot;)
abline(lm(explained_var~volumes),col=&quot;red&quot;)</code></pre>
<p><img src="Descriptive_stats_files/figure-html/unnamed-chunk-1-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="parallel-analysis-suggests-to-extract-more-pcs-for-larger-networks" class="section level3">
<h3>Parallel analysis suggests to extract more PCs for larger networks</h3>
<pre class="r"><code>networks&lt;-c(&quot;central&quot;,&quot;cingulo&quot;,&quot;default&quot;,&quot;hippo&quot;,&quot;multiple&quot;,&quot;pfit&quot;,&quot;salience&quot;,&quot;sensori&quot;,&quot;temporo&quot;,&quot;whole_brain&quot;)
volumes&lt;-table$number_included
components&lt;-c(2,2,3,4,2,7,2,2,7,14)

test&lt;-cbind(networks,volumes,components)

cor.test(volumes,components,data=test)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  volumes and components
## t = 14.313, df = 8, p-value = 5.54e-07
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.9191324 0.9956563
## sample estimates:
##      cor 
## 0.981028</code></pre>
<pre class="r"><code>plot(volumes,components,ylab=&quot;PCs with eigenvalues above chance&quot;,xlab=&quot;Number of included volumes&quot;)
abline(lm(components~volumes),col=&quot;red&quot;)</code></pre>
<p><img src="Descriptive_stats_files/figure-html/pa-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="a-priori-networks-explain-more-variance-than-networks-with-randomly-included-volumes" class="section level2">
<h2>A priori networks explain more variance than networks with randomly included volumes</h2>
<p>We added this analysis to formally test whether explained variances by the first underlying PC were larger for a priori networks than they were for networks including random volumes. The simulations are repeated for different amounts of randomly included volumes (800 times each), as the first PC of a network with fewer volumes generally explains less variance compared with networks including more volumes.</p>
<p>We ask this question, because it may invalidate a priori network characterisations if we obtain the same amounts of explained variances for random network characterisations.</p>
<pre class="r"><code># read in genetic correlation matrix - whole brain 
workingd&lt;-getwd()
temporarywd&lt;-paste0(workingd,&quot;/data_my_own/ldsc/&quot;)
setwd(temporarywd)

load(&quot;whole_brain.RData&quot;)
ldscoutput&lt;-LDSCoutput_wholebrain

# name cells in genetic correlation matrix
dimnames(ldscoutput$S_Stand)[[1]]&lt;-dimnames(ldscoutput$S)[[2]]
dimnames(ldscoutput$S_Stand)[[2]]&lt;-dimnames(ldscoutput$S)[[2]]
ldscoutput$S_Stand&lt;-ldscoutput$S_Stand

# randomly sample brain volumes to be included in a network
all_names&lt;-dimnames(ldscoutput$S)[[2]]

# make table to save output
save_random&lt;-data.frame(matrix(ncol=2))
colnames(save_random)&lt;-c(&quot;number_included&quot;,&quot;random_R2&quot;)

# set seed for replicability
set.seed(1234)

# simulate for each number of included volumes in a priori networks
number_included&lt;-c(8,10,12,16,30,36)

# set number of repititions per numver of included volumes
reps&lt;-800

for(j in number_included){
    i&lt;-0

      # repeat reps for each number of included volumes until reps is reached
      repeat{
        i&lt;-i+1

        # determine row to be printed in 
        row&lt;-ifelse(nrow(save_random) == 0, 1,nrow(save_random)+1)

        # save number of volumes included
        save_random[row,&quot;number_included&quot;]&lt;-j 
        
        # randomly select volumes 
        random_names&lt;-sample(all_names, size=j)

        # eigendecomposition
        matrix&lt;-ldscoutput$S_Stand[random_names,random_names]
        eigenvectors&lt;-eigen(matrix)$vectors
        eigenvalues&lt;-eigen(matrix)$values
        random_R2&lt;-(eigenvalues/sum(eigenvalues)*100)[1]
        
        #save in table called save_random
        save_random[row,&quot;random_R2&quot;]&lt;-random_R2
    
          if(i&gt;=reps){
            break
          }
      }
        
}

# calculate statistics per number of included volumes

# mean
results_mean&lt;-aggregate(save_random$random_R2, list(save_random$number_included), mean)
colnames(results_mean)&lt;-c(&quot;number_included&quot;,&quot;random_R2_mean&quot;)

#sd
results_sd&lt;-aggregate(save_random$random_R2, list(save_random$number_included), sd)
colnames(results_sd)&lt;-c(&quot;number_included&quot;,&quot;random_R2_sd&quot;)
results&lt;-merge(results_mean,results_sd,by=&quot;number_included&quot;)

#se
results_se&lt;-cbind(number_included=results_sd$number_included, random_R2_se=results_sd$random_R2_sd/sqrt(reps))
results&lt;-merge(results,results_se,by=&quot;number_included&quot;)

# confidence intervals
results$lower_ci&lt;-with(results, random_R2_mean-(1.96*random_R2_se))
results$upper_ci&lt;-with(results, random_R2_mean+(1.96*random_R2_se))

# round and merge confidence intervals for display
results$lower_ci&lt;-round(results$lower_ci,digits = 2)
results$upper_ci&lt;-round(results$upper_ci,digits = 2)

results$CI&lt;-paste(results$lower_ci,results$upper_ci,sep=&quot; - &quot;)

# merge with empirical results
random_empirical&lt;-merge(results[,c(&quot;number_included&quot;,&quot;random_R2_mean&quot;,&quot;CI&quot;)],table[,c(&quot;networks&quot;,&quot;explained&quot;,&quot;number_included&quot;)],by=&quot;number_included&quot;)

kable(random_empirical,digits = 2,caption=&quot;Mean explained variance and 95% confidence intervals for networks with randomly included volumes&quot;)</code></pre>
<table>
<caption>Mean explained variance and 95% confidence intervals for networks with randomly included volumes</caption>
<thead>
<tr class="header">
<th align="right">number_included</th>
<th align="right">random_R2_mean</th>
<th align="left">CI</th>
<th align="left">networks</th>
<th align="right">explained</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">8</td>
<td align="right">46.37</td>
<td align="left">46.05 - 46.68</td>
<td align="left">central_exec</td>
<td align="right">65.23</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">45.01</td>
<td align="left">44.72 - 45.31</td>
<td align="left">salience</td>
<td align="right">49.05</td>
</tr>
<tr class="odd">
<td align="right">10</td>
<td align="right">45.01</td>
<td align="left">44.72 - 45.31</td>
<td align="left">cingulo</td>
<td align="right">47.50</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="right">43.99</td>
<td align="left">43.72 - 44.25</td>
<td align="left">hippocampal</td>
<td align="right">47.63</td>
</tr>
<tr class="odd">
<td align="right">12</td>
<td align="right">43.99</td>
<td align="left">43.72 - 44.25</td>
<td align="left">multiple</td>
<td align="right">55.23</td>
</tr>
<tr class="even">
<td align="right">12</td>
<td align="right">43.99</td>
<td align="left">43.72 - 44.25</td>
<td align="left">sensori</td>
<td align="right">55.42</td>
</tr>
<tr class="odd">
<td align="right">16</td>
<td align="right">42.61</td>
<td align="left">42.38 - 42.83</td>
<td align="left">default_mode</td>
<td align="right">51.78</td>
</tr>
<tr class="even">
<td align="right">30</td>
<td align="right">40.86</td>
<td align="left">40.72 - 41.01</td>
<td align="left">temporo</td>
<td align="right">46.92</td>
</tr>
<tr class="odd">
<td align="right">36</td>
<td align="right">40.59</td>
<td align="left">40.45 - 40.72</td>
<td align="left">p_fit</td>
<td align="right">47.56</td>
</tr>
</tbody>
</table>
<p>All nine <em>a priori</em> networks explain more variance than networks with randomly selected volumes. Comparisons must be made for matching numbers of included volumes (i.e. the 39% explained variance by the central executive network should be compared with the mean explained variance for networks with 8 randomly selected regional volumes).</p>
</div>
</div>

&nbsp;
<hr />
<a href = "https://www.kcl.ac.uk/">
<p style="text-align: center"><img src="KCL_logo.jpg" href="https://www.kcl.ac.uk/" style="width:70px;height:50px"> 
</a>
</p>

<a href = "https://www.kcl.ac.uk/people/anna-furtjes">
<p style="text-align: center;">By Anna Elisabeth Fürtjes</a></p>
<p style="text-align: center;"><span style="color: #808080;"><em>anna.furtjes@kcl.ac.uk</em></span></p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <a href="https://twitter.com/Anna_Furtjes" class="fa fa-twitter"></a>
</p>

&nbsp;


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
